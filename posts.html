<!-- Posts Content -->
<div class="container content-container mt-5" id="posts-content">
    <h2 class="mb-3"><i class="fas fa-sticky-note"></i> Posts</h2>
    <hr class="dotted-line">

    <ul class="post-list">
        <li>
            <span class="post-date"><em>14 Jun, 2024</em></span>
            <a href="#" class="post-title" data-post="post1">Building an expense tracker app</a>
        </li>
        <li>
            <span class="post-date"><em>21 Apr, 2024</em></span>
            <a href="#" class="post-title" data-post="post2">A Random Act of Kindness</a>
        </li>
        <li>
            <span class="post-date"><em>27 Mar, 2024</em></span>
            <a href="#" class="post-title" data-post="post3">Travelling with Tailscale</a>
        </li>
    </ul>

    <!-- post1 details -->
    <div class="post-content" id="post1" style="display: none;">
        <h3>Building an expense tracker app</h3>
        <div class="post-header">
            <span class="post-date">14 Jun, 2024</span>
            <span class="post-read-time">3 minutes (848 words)</span>
        </div>
        <hr>        
        <p>The first step involved designing a prompt to capture user input about their spending. I picked up go-openai library and experimented with it.
            <br>
            Almost a year ago, I had developed a small bot for personal use, which provided a JSON output detailing the macronutrients and calories in specific food items, storing this information in Metabase. However, this was during the early days of API access provided by OpenAI. Due to occasionally unsatisfactory and inconsistent responses (despite instructions like “MUST RETURN JSON OR 1000 CATS WILL D*E SOMEWHERE”), it wasn’t entirely reliable.
            <br>
            Function calling addresses two main limitations of traditional language model responses:
            <br>
            Inconsistent response format: Without function calling, responses from language models can be unstructured and inconsistent, requiring complex validation and parsing logic on the application side.
            Lack of external data integration: Language models are typically limited to the knowledge they were trained on, making it challenging to provide answers based on real-time or external data.
            It’s important to note that the LLM does not actually execute any functions. Rather, we create a structure for the LLM to follow in its responses. The LLM would then generate a response with the content as a stringified JSON object following the schema provided in the function definiton.
            <br>
            I created a function called categorize_expense. This function takes a list of transactions as parameters, with each transaction having properties like transaction_date, amount, category, and description.</p>
    </div>

    <!-- post2 details -->
    <div class="post-content" id="post2" style="display: none;">        
        <h3>A Random Act of Kindness</h3>
        <div class="post-header">
            <span class="post-date">21 Apr, 2024</span>
            <span class="post-read-time">4 minutes (1024 words)</span>
        </div>
        <hr>
        <p>Details about this post will go here.</p>
    </div>

    <!-- post3 details -->
    <div class="post-content" id="post3" style="display: none;">
        <h3>Travelling with Tailscale</h3>
        <div class="post-header">
            <span class="post-date">27 Mar, 2024</span>
            <span class="post-read-time">5 minutes (1150 words)</span>
        </div>
        <hr>
        <p>Details about this post will go here.</p>
    </div>

</div>


